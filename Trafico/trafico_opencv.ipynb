{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "min_contour_width = 40      # establecen el ancho mínimo de los contornos\n",
    "min_contour_height = 40     # establecen el alto mínimo de los contornos\n",
    "offset = 3                  # margen que se deja alrededor de la línea en la que se cuentan los coches que cruzan\n",
    "line_height = 500           # altura de la línea en la que se cuentan los coches\n",
    "matches = []                # lista que almacena las coordenadas 'x' e 'y' de los centros de los contornos detectados\n",
    "cars = 0                    # recuento de coches detectados\n",
    " \n",
    " \n",
    "def get_centrolid(x, y, w, h):\n",
    "    # toma las coordenadas x, y, w y h de un contorno y devuelve las coordenadas del centroide\n",
    "    x1 = int(w / 2)\n",
    "    y1 = int(h / 2)\n",
    " \n",
    "    cx = x + x1\n",
    "    cy = y + y1\n",
    "    return cx, cy\n",
    " \n",
    "\n",
    "cap = cv2.VideoCapture('trafico01.mp4')     # abre el video \n",
    "\n",
    "\n",
    "if cap.isOpened(): ret, frame1 = cap.read() # si se ha abierto el video, frame1 = primer frame\n",
    "else: ret = False                           # si no; no entra al bucle\n",
    "# leen 2 frames consecutivos del video\n",
    "ret, frame1 = cap.read()\n",
    "ret, frame2 = cap.read()\n",
    " \n",
    " \n",
    "while ret:  # mientras haya frames disponibles para leer\n",
    "    # calcula la diferencia absoluta entre los 2 frames\n",
    "    dif = cv2.absdiff(frame1, frame2)                 \n",
    "    # convierte la imagen a escala de grises\n",
    "    grey = cv2.cvtColor(dif, cv2.COLOR_BGR2GRAY)      \n",
    "    # suaviza la imagen mediante el uso de una máscara gaussiana\n",
    "    blur = cv2.GaussianBlur(grey, (5, 5), 0)          \n",
    "    # aplica un umbral a la imagen suavizada para convertirla en una imagen binaria\n",
    "    ret, th = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)       \n",
    "    # dilata la imagen binaria para expandir las regiones blancas de la imagen binaria (pixeles adyacentes también se vuelvan blancos)\n",
    "    dilated = cv2.dilate(th, np.ones((3, 3)))                       \n",
    "    # crea un kernel que se utilizará en las operaciones morfológicas subsiguientes. El kernel será una elipse con un tamaño de (2, 2)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))   \n",
    "    # dilata y erosiona la imagen para cerrar pequeños agujeros dentro de los objetos\n",
    "    closing = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, kernel)    \n",
    "    # detectar contornos en la imagen (Los contornos se devuelven como una lista de puntos)\n",
    "    contours, h = cv2.findContours(closing, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n",
    "    # itera a través de la lista de contornos y asigna el índice y el contorno a las variables i y c\n",
    "    for(i, c) in enumerate(contours):   \n",
    "        # obtiene los valores de (x, y) para el punto más a la izquierda y más arriba del rectángulo que envuelve el contorno \n",
    "        # y los valores de w y h para el ancho y alto del rectángulo, respectivamente.\n",
    "        (x, y, w, h) = cv2.boundingRect(c)  \n",
    "        # un contorno es válido si su ancho y alto son mayores o iguales a los valores mínimos establecidos para el ancho y alto del contorno\n",
    "        contour_valid = (w >= min_contour_width) and (h >= min_contour_height)  \n",
    "        # si el contorno no es válido, se salta al siguiente contorno\n",
    "        if not contour_valid: continue  \n",
    "        # dibuja un rectángulo alrededor del contorno en la imagen\n",
    "        cv2.rectangle(frame1, (x-10, y-10), (x+w+10, y+h+10), (255, 0, 0), 2)   \n",
    "        # dibuja una línea en la imagen\n",
    "        cv2.line(frame1, (215, line_height), (1185, line_height), (200, 255, 0), 2) \n",
    "        # obtiene el centro del contorno y lo almacena en la variable centrolid.\n",
    "        centrolid = get_centrolid(x, y, w, h)   \n",
    "        # agrega el centro del contorno a la lista matches\n",
    "        matches.append(centrolid)               \n",
    "        # dibuja un círculo en el centro del contorno en la imagen frame1.\n",
    "        cv2.circle(frame1, centrolid, 1, (255, 0, 300), 3)\n",
    "        # obtienen el centro del contorno y lo almacenan en las variables cx y cy   \n",
    "        cx, cy = get_centrolid(x, y, w, h)      \n",
    "        # itera a través de la lista matches y cuenta el número de contornos que cruzan la línea dibujada en la imagen\n",
    "        for (x, y) in matches:                  \n",
    "            # Si el eje 'y' del centro del contorno está dentro de un cierto margen de la línea (determinado por la variable offset):\n",
    "            if y < (line_height+offset) and y > (line_height-offset): \n",
    "                # se aumenta el contador de coches  \n",
    "                cars = cars+1           \n",
    "                # se elimina el contorno de la lista matches\n",
    "                matches.remove((x, y))\n",
    "    \n",
    "    # pone texto en la pantalla\n",
    "    cv2.putText(frame1, \"Total de coches detectados: \" + str(cars), (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 0, 0), 2)\n",
    " \n",
    "    cv2.imshow(\"Vehicle Detection\", frame1)     # muestra el video\n",
    "    #cv2.imshow(\"Difference\" , th)              # muestra e video con el fondo negro coches en blanco\n",
    "    if cv2.waitKey(1) == 27: break              # acabar si se preciona la tecla esc    \n",
    "    frame1 = frame2                             # el frame1 pasa a ser el frame2, ya que los comparamos arriba\n",
    "    ret, frame2 = cap.read()                    # frame2 pasa a ser el siguiente frame y frame1 sera el anterior\n",
    "\n",
    "cv2.destroyAllWindows()                         # elimina todas las pestañas\n",
    "cap.release()                                   # cierra el archivo de video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<class 'cv2.CascadeClassifier'> returned a result with an exception set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\persistence.cpp:692: error: (-5:Bad argument) Input file is invalid in function 'cv::FileStorage::Impl::open'\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m video \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m\"\u001b[39m\u001b[39mtrafico01.mp4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39m# Crea un detector de objetos\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m detector \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mCascadeClassifier(\u001b[39m\"\u001b[39;49m\u001b[39mcars.xml\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[39m# Si estás procesando un vídeo, obtén el siguiente fotograma\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     success, image \u001b[39m=\u001b[39m video\u001b[39m.\u001b[39mread()\n",
      "\u001b[1;31mSystemError\u001b[0m: <class 'cv2.CascadeClassifier'> returned a result with an exception set"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture(\"trafico01.mp4\")\n",
    "\n",
    "# Crea un detector de objetos\n",
    "detector = cv2.CascadeClassifier(\"cars.xml\")\n",
    "\n",
    "while True:\n",
    "    # Si estás procesando un vídeo, obtén el siguiente fotograma\n",
    "    success, image = video.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Detecta los coches en la imagen o vídeo\n",
    "    cars = detector.detectMultiScale(image)\n",
    "\n",
    "    # Recorre todos los coches detectados\n",
    "    for i, (x, y, w, h) in enumerate(cars):\n",
    "        # Dibuja un rectángulo alrededor del coche\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "        # Escribe el ID del coche en el rectángulo\n",
    "        cv2.putText(image, str(i), (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    # Muestra los resultados en una ventana de visualización\n",
    "    cv2.imshow(\"Imagen con coches detectados\", image)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "# Cierra la ventana de visualización y libera los recursos utilizados por cv2\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e98996b20e2062bc07e1c54a0b223eff6c9ad2af4beff5a020f2447f9c6ce03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
